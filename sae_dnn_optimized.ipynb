{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70c83bc",
   "metadata": {},
   "source": [
    "# Optimized SAE + DNN Pipeline for AGB Estimation\n",
    "This notebook implements an optimized Sparse Autoencoder (SAE) + DNN workflow with the following improvements:\n",
    "- Dynamic layer sizing\n",
    "- EarlyStopping for AE and DNN\n",
    "- Validation splits\n",
    "- L1 regularization tuning\n",
    "- Dropout for DNN\n",
    "- Easily tunable latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Autoencoder Class\n",
    "# -------------------------\n",
    "class AutoencoderFeatureExtractor:\n",
    "    def __init__(self, input_dim, latent_dim=64, l1_reg=1e-5, hidden_1=None, hidden_2=None):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.l1_reg = l1_reg\n",
    "        self.hidden_1 = hidden_1 if hidden_1 else max(128, input_dim // 2)\n",
    "        self.hidden_2 = hidden_2 if hidden_2 else max(64, input_dim // 4)\n",
    "        self.encoder = None\n",
    "        self.autoencoder = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        # Encoder\n",
    "        x = Dense(self.hidden_1, activation='relu')(input_layer)\n",
    "        x = Dense(self.hidden_2, activation='relu')(x)\n",
    "        bottleneck = Dense(self.latent_dim, activation='relu', activity_regularizer=l1(self.l1_reg))(x)\n",
    "        # Decoder\n",
    "        x = Dense(self.hidden_2, activation='relu')(bottleneck)\n",
    "        x = Dense(self.hidden_1, activation='relu')(x)\n",
    "        output_layer = Dense(self.input_dim, activation='linear')(x)\n",
    "\n",
    "        autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "        self.encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
    "\n",
    "        autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        return autoencoder\n",
    "\n",
    "    def train(self, X, epochs=200, batch_size=32, validation_split=0.1):\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        self.autoencoder.fit(\n",
    "            X, X,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=validation_split,\n",
    "            shuffle=True,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def extract_features(self, X):\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# DNN Builder and Trainer\n",
    "# -------------------------\n",
    "def build_dnn(input_dim, hidden_1=128, hidden_2=64, dropout_rate=0.2, lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_1, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(hidden_2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_dnn(model, X_train, y_train, X_val, y_val, epochs=200, batch_size=32):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Pipeline Function\n",
    "# -------------------------\n",
    "def run_sae_dnn_pipeline(data_path, target_col='Target', latent_dim=64):\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.drop(columns=[col for col in ['origin', 'Origin', 'status', 'Status'] if col in df.columns])\n",
    "    X = df.drop(columns=[target_col]).values\n",
    "    y = df[target_col].values\n",
    "\n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split train/test\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Train Autoencoder\n",
    "    ae = AutoencoderFeatureExtractor(input_dim=X_train_raw.shape[1], latent_dim=latent_dim)\n",
    "    ae.train(X_train_raw)\n",
    "\n",
    "    # Extract latent features\n",
    "    X_train_latent = ae.extract_features(X_train_raw)\n",
    "    X_test_latent = ae.extract_features(X_test_raw)\n",
    "\n",
    "    # Split latent features for DNN validation\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_latent, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Train DNN\n",
    "    dnn = build_dnn(input_dim=X_train_final.shape[1])\n",
    "    dnn = train_dnn(dnn, X_train_final, y_train_final, X_val, y_val)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = dnn.predict(X_test_latent).flatten()\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"RÂ²: {r2:.4f}, MAE: {mae:.2f}, MSE: {mse:.2f}\")\n",
    "    return r2, mae, mse\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# run_sae_dnn_pipeline('/content/4_tvol_lidarLiveQMinMax.csv', latent_dim=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060afcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example Usage for LiDAR Q dataset\n",
    "result = run_sae_dnn_pipeline('/content/4_tvol_lidarLiveQMinMax.csv', latent_dim=128)\n",
    "print(\"Final Results:\", result)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
